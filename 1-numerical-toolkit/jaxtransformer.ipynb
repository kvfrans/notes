{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "import jax\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The `jaxtransformer` Library\n",
    "\n",
    "Along with these notes, we've compiled a small library for training transformer models, known as `jaxtransformer`. You can see the source code at [https://github.com/kvfrans/jaxtransformer](https://github.com/kvfrans/jaxtransformer). \n",
    "\n",
    "These days, almost every model uses a Transformer backbone. Rather than repeat this code every time, we found it might be cleaner to put all the common functions into a helper library. We utilize the `jaxtransformer` library throughout these notes. I encourage you to use these utilities as a starting point for any projects that you see fit. In the repo, there is example code to train a diffusion model, a language model, or an image classifier in `examples/`. \n",
    "\n",
    "The `jaxtransformer` is more like a set of useful utilities. There are only three main files:\n",
    "- `transformer.py`: Main transformer backbone, does not import any other code.\n",
    "- `modalities.py`: Useful modules such as token embedding, patch embedding, positional encoding.\n",
    "- `configs.py`: Default hyperparameters for model sizes and optimizers.\n",
    "\n",
    "Along with some nice utilities:\n",
    "- `utils/checkpoint.py`: Minimal checkpointer for flax networks.\n",
    "- `utils/datasets.py`: Minimal dataloader using TFDS, see [https://github.com/kvfrans/tfds_builders](https://github.com/kvfrans/tfds_builders).\n",
    "- `utils/sharding.py`: Minimal implementation of fully-sharded data parallelism.\n",
    "- `utils/train_state.py`: Simple train state object to hold parameters and model definition.\n",
    "- `utils/wandb.py`: For logging to wandb.\n",
    "\n",
    "There are also some generative model specific utilities:\n",
    "- `utils/fid.py`: Utilities to measure Frechet Inception Distance, see [https://github.com/kvfrans/jax-fid-parallel](https://github.com/kvfrans/jax-fid-parallel).\n",
    "- `utils/pretrained_resnet.py`: Used for FID measurement.\n",
    "- `utils/stable_vae.py`: Implements the Stable Diffusion VAE, for training generative models over latent representations.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "frog",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
